{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a955a2ad",
   "metadata": {},
   "source": [
    "# 1. Classification and Regression Trees\n",
    "## Decision tree for classification\n",
    "\n",
    "\n",
    "**Classification-tree**\n",
    "\n",
    "Sequence of if-else questions about individual features.\n",
    "\n",
    "* Objective: infer class labels.\n",
    "\n",
    "* Able to capture non-linear relationships between features and labels.\n",
    "\n",
    "* Don't require feature scaling (ex:Standardization,..)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "390594bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# Import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Import accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Split the dataset into 80% train, 20% test\n",
    "# X_train, X_test, y_train, y_test= train_test_split(X, y,\n",
    "#                                                    test_size=0.2,\n",
    "#                                                    stratify=y,\n",
    "#                                                    random_state=1)\n",
    "# # Instantiate dt\n",
    "\n",
    "# dt = DecisionTreeClassifier(max_depth=2, random_state=1)\n",
    "\n",
    "# # Fit dt to the training set\n",
    "# dt.fit(X_train,y_train) \n",
    "# # Predict the test set labels\n",
    "# y_pred = dt.predict(X_test)\n",
    "# # Evaluate the test-set accuracy\n",
    "# accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5141a4",
   "metadata": {},
   "source": [
    "**Decision Regions**\n",
    "> `Decision region`: region in the feature space where all instances areas signed to one class label.\n",
    "\n",
    "> `Decision Boundary`: surface separating different decision regions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e7c960",
   "metadata": {},
   "source": [
    "### Train your first classification tree\n",
    "We'll work with the Wisconsin Breast Cancer Dataset from the UCI machine learning repository. We'll predict whether a tumor is malignant or benign based on two features: the mean radius of the tumor (`radius_mean`) and its mean number of concave points (`concave points_mean`).\n",
    "<a href=\"https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data\">DATASET</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2e33e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "wbc = pd.read_csv('wbc.csv')\n",
    "wbc['Diagnosis_num'] = wbc['diagnosis'].map({'B':0, 'M':1})\n",
    "X = wbc[['radius_mean', 'concave points_mean']].values\n",
    "y = wbc['Diagnosis_num'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "19348e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# Import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Import accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y,\n",
    "                                                   test_size=0.2,\n",
    "                                                   stratify=y,\n",
    "                                                   random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d9e04650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a DecisionTreeClassifier 'dt' with a maximum depth of 6\n",
    "dt = DecisionTreeClassifier(max_depth=6, random_state=1)\n",
    "\n",
    "# Fit dt to the training set\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = dt.predict(X_test)\n",
    "print(y_pred[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ce5149",
   "metadata": {},
   "source": [
    "> You can see the first five predictions made by the fitted tree on the test set in the console. \n",
    "\n",
    "### Evaluate the classification tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad559bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.91\n"
     ]
    }
   ],
   "source": [
    "# Import accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "# Compute test set accuracy  \n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Test set accuracy: {:.2f}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75643708",
   "metadata": {},
   "source": [
    "> Using only two features, your tree was able to achieve an accuracy of 89%!\n",
    "\n",
    "### Logistic regression vs classification tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d83f4edc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LogisticRegression(random_state=1),\n",
       " DecisionTreeClassifier(max_depth=6, random_state=1)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# Import LogisticRegression from sklearn.linear_model\n",
    "from sklearn.linear_model import  LogisticRegression\n",
    "\n",
    "# Instatiate logreg\n",
    "logreg = LogisticRegression(random_state=1)\n",
    "\n",
    "# Fit logreg to the training set\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Define a list called clfs containing the two classifiers logreg and dt\n",
    "clfs = [logreg, dt]\n",
    "clfs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d42b890",
   "metadata": {},
   "source": [
    "## Classification tree Learning\n",
    "\n",
    "\n",
    "**Building Blocks of a Decision-Tree**\n",
    "\n",
    "* Decision-Tree: data structure consisting of a hierarchy of nodes.\n",
    "\n",
    "* Node: question or prediction.\n",
    "\n",
    "**Building Blocks of a Decision-Tree**\n",
    "\n",
    "Three kinds of nodes:\n",
    "\n",
    "* Root: no parent node, question giving rise to two children nodes.\n",
    "* Internalnode: one parent node, question giving rise to two children nodes.\n",
    "* Leaf:one parent node, no children nodes --> prediction.\n",
    "\n",
    "**Information Gain(IG)**\n",
    "\n",
    "Criteria to measure the impurity of a node $I(node)$:\n",
    "* gini index\n",
    "* entropy\n",
    "\n",
    "**Classification-Tree Learning**\n",
    "* Nodes are grown recursively.\n",
    "* At each node, split the data based on:\n",
    "    * feature $f$ and split-point $sp$ to maximize $IG(node)$.\n",
    "* If $IG(node)=0$, declare the node a leaf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a70e5b9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8245614035087719"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# Import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Import accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split dataset into 80% train, 20% test\n",
    "\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y,\n",
    "                                                   test_size=0.2,\n",
    "                                                   stratify=y,\n",
    "                                                   random_state=1)\n",
    "\n",
    "# Instantiate dt, set 'criterion' to 'gini'\n",
    "\n",
    "dt = DecisionTreeClassifier(criterion='gini', random_state=1)\n",
    "\n",
    "# Fit dt to the training set\n",
    "\n",
    "dt.fit(X_train,y_train)\n",
    "\n",
    "# Predict test-set labels\n",
    "\n",
    "y_pred= dt.predict(X_test)\n",
    "\n",
    "# Evaluate test-set accuracy\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc313ffb",
   "metadata": {},
   "source": [
    "### Using entropy as a criterion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5f1ef1eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=8, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=8, random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_depth=8, random_state=1)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import DecisionTreeClassifier from sklearn.tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Instantiate dt_entropy, set 'entropy' as the information criterion\n",
    "dt_entropy = DecisionTreeClassifier(max_depth=8, criterion='entropy', random_state=1)\n",
    "\n",
    "# Fit dt_entropy to the training set\n",
    "dt_entropy.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "354f30ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=8, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=8, random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=8, random_state=1)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import DecisionTreeClassifier from sklearn.tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Instantiate dt_entropy, set 'entropy' as the information criterion\n",
    "dt_gini = DecisionTreeClassifier(max_depth=8, criterion='gini', random_state=1)\n",
    "\n",
    "# Fit dt_entropy to the training set\n",
    "dt_gini.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0df5e585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy achieved by using entropy: 0.886\n",
      "Accuracy achieved by using the gini index: 0.833\n"
     ]
    }
   ],
   "source": [
    "# Import accuracy_score from sklearn.metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Use dt_entropy to predict test set labels\n",
    "y_pred = dt_entropy.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy_entropy\n",
    "accuracy_entropy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "y_pred = dt_gini.predict(X_test)\n",
    "accuracy_gini = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print accuracy_entropy\n",
    "print(f'Accuracy achieved by using entropy: {accuracy_entropy:.3f}')\n",
    "\n",
    "# Print accuracy_gini\n",
    "print(f'Accuracy achieved by using the gini index: {accuracy_gini:.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533c1158",
   "metadata": {},
   "source": [
    "> Notice how the two models achieve almost the same accuracy. Most of the time, the gini index and entropy lead to the same results. The gini index is slightly faster to compute and is the default criterion used in the DecisionTreeClassifier model of scikit-learn.\n",
    "\n",
    "## Decision tree for regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "855c4f82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>displ</th>\n",
       "      <th>hp</th>\n",
       "      <th>weight</th>\n",
       "      <th>accel</th>\n",
       "      <th>origin</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>88</td>\n",
       "      <td>3139</td>\n",
       "      <td>14.5</td>\n",
       "      <td>US</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>193</td>\n",
       "      <td>4732</td>\n",
       "      <td>18.5</td>\n",
       "      <td>US</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.1</td>\n",
       "      <td>91.0</td>\n",
       "      <td>60</td>\n",
       "      <td>1800</td>\n",
       "      <td>16.4</td>\n",
       "      <td>Asia</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.5</td>\n",
       "      <td>250.0</td>\n",
       "      <td>98</td>\n",
       "      <td>3525</td>\n",
       "      <td>19.0</td>\n",
       "      <td>US</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34.3</td>\n",
       "      <td>97.0</td>\n",
       "      <td>78</td>\n",
       "      <td>2188</td>\n",
       "      <td>15.8</td>\n",
       "      <td>Europe</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  displ   hp  weight  accel  origin  size\n",
       "0  18.0  250.0   88    3139   14.5      US  15.0\n",
       "1   9.0  304.0  193    4732   18.5      US  20.0\n",
       "2  36.1   91.0   60    1800   16.4    Asia  10.0\n",
       "3  18.5  250.0   98    3525   19.0      US  15.0\n",
       "4  34.3   97.0   78    2188   15.8  Europe  10.0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto = pd.read_csv('auto.csv')\n",
    "auto.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "219110ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='displ', ylabel='mpg'>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.scatterplot(x='displ', y='mpg', data=auto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab32f9a3",
   "metadata": {},
   "source": [
    "> Mpg consumption increases non-linearly with displacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a8e1c93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = auto['displ'].values\n",
    "y = auto['mpg'].values\n",
    "### Important reshape\n",
    "X = X.reshape(-1, 1)\n",
    "y = y.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d2f35059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import DecisionTreeRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "# Import train_test_split \n",
    "from sklearn.model_selection import train_test_split\n",
    "# Import mean_squared_error as MSE\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "# Split data into 80% train and 20% test\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y,\n",
    "                                                       test_size=0.2,\n",
    "                                                       random_state=3)\n",
    "\n",
    "# Instantiate a DecisionTreeRegressor 'dt'\n",
    "\n",
    "dt = DecisionTreeRegressor(max_depth=4,\n",
    "                           min_samples_leaf=0.1,\n",
    "                           random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "97cbfbc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.102306888903137\n"
     ]
    }
   ],
   "source": [
    "# Fit 'dt' to the training-set\n",
    "dt.fit(X_train, y_train)\n",
    "# Predict test-set labels\n",
    "y_pred = dt.predict(X_test)\n",
    "# Compute test-set MSE\n",
    "mse_dt =  MSE(y_test, y_pred)\n",
    "# Compute test-set RMSE\n",
    "rmse_dt = mse_dt**(1/2)\n",
    "# Print rmse_dt\n",
    "print(rmse_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa5a5ec",
   "metadata": {},
   "source": [
    "### Train your first regression tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "214cba3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(392, 7)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto = pd.read_csv('auto.csv')\n",
    "auto.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1cfb9adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(392, 3)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origin = pd.get_dummies(auto['origin'])\n",
    "origin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "701b549f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(392, 10)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_auto = auto.merge(origin, left_index=True, right_index=True)\n",
    "cleaned_auto.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "36e6e12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_auto = cleaned_auto.drop('origin', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "27b11cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(392, 9)\n",
      "(392, 1)\n"
     ]
    }
   ],
   "source": [
    "y = auto['displ'].values\n",
    "y = y.reshape(-1,1)\n",
    "print(X.shape)\n",
    "X = cleaned_auto.drop('displ', axis=1)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fa00ad66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeRegressor(max_depth=8, min_samples_leaf=0.13, random_state=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(max_depth=8, min_samples_leaf=0.13, random_state=3)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeRegressor(max_depth=8, min_samples_leaf=0.13, random_state=3)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import DecisionTreeRegressor from sklearn.tree\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Instantiate dt\n",
    "dt = DecisionTreeRegressor(max_depth=8,\n",
    "             min_samples_leaf=0.13,\n",
    "            random_state=3)\n",
    "\n",
    "# Fit dt to the training set\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4975b1d0",
   "metadata": {},
   "source": [
    "### Evaluate the regression tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "71b7672d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set RMSE of dt: 5.04\n"
     ]
    }
   ],
   "source": [
    "# Import mean_squared_error from sklearn.metrics as MSE\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "# Compute y_pred\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "# Compute mse_dt\n",
    "mse_dt =  MSE(y_test, y_pred)\n",
    "\n",
    "# Compute rmse_dt\n",
    "rmse_dt = mse_dt**(1/2)\n",
    "\n",
    "# Print rmse_dt\n",
    "print(\"Test set RMSE of dt: {:.2f}\".format(rmse_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac3dbfc",
   "metadata": {},
   "source": [
    "# 2. The Bias-Variance Tradeoff\n",
    "\n",
    "## Generalization Error\n",
    "\n",
    "\n",
    "**Goals of Supervised Learning** \n",
    "1. Find a model $\\hat{f}$ that best approximates $f$\n",
    "2. $\\hat{f}$ can be Logistic Regression, Decision Tree, Neural Network\n",
    "3. Discard noise as much as possible.\n",
    "4. Endgoal: $\\hat{f}$ should achieve a low predictive error on unseen datasets.\n",
    "\n",
    "**Difficulties in Approximating $f$** \n",
    "\n",
    "* **Overfitting:** $\\hat{f}(x)$ fits the training set noise.\n",
    "\n",
    "* **Undering:** $\\hat{f}$ is not flexible enough to approximate $f$.\n",
    "\n",
    "\n",
    "### Generalization Error\n",
    "\n",
    "* **Generalization Error of $\\hat{f}$:** Does $\\hat{f}$ generalize well on unseen data?\n",
    "* It can be decomposed as follows: Generalization Error of\n",
    "\n",
    "$\\hat{f} = bias^2 + variance + irreducible error$\n",
    "\n",
    "##### Bias\n",
    "\n",
    "**Bias:** error term that tells you, on average, how much $\\hat{f} â‰  f$\n",
    "\n",
    "##### Variance\n",
    "**Variance:** tells you how much $\\hat{f}$ is inconsistent over different training sets.\n",
    "\n",
    "\n",
    "> **As the complexity of $\\hat{f}$ increases, the bias term decreases while the variance term increases.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5446f2c7",
   "metadata": {},
   "source": [
    "### Diagnose bias and variance problems\n",
    "\n",
    "##### Estimating the Generalization Error\n",
    "\n",
    "* How do we estimate the generalization error of a model?\n",
    "* Cannot be done directly because:\n",
    "\n",
    "    * $f$ is unknown, usually you only have one dataset, noise is unpredictable.\n",
    "\n",
    "**Solution:**\n",
    "\n",
    "* split the data to training and test sets\n",
    "\n",
    "* fit $\\hat{f}$ to the training set\n",
    "* evaluate the error of $\\hat{f}$ on the unseen test set\n",
    "* generalization error of $\\hat{f}â‰ˆ$ test set error of $\\hat{f}$.\n",
    "\n",
    "\n",
    "##### Better Model Evaluation with Cross-Validation \n",
    "\n",
    "* Test set should not be touched until we are confident about $\\hat{f}$'s performance.\n",
    "* Evaluating $\\hat{f}$ on training set: biased estimate, $\\hat{f}$ has already seen all training points.\n",
    "* **Solution** â†’ Cross-Validation(CV):\n",
    "    * K-FoldCV\n",
    "    * Hold-OutCV\n",
    "    \n",
    "###### Diagnose Variance Problems \n",
    "* If $\\hat{f}$ suffers from high variance: CV error of  > training set error of.\n",
    "\n",
    "* $\\hat{f}$ is said to overfit the training set. To remedy overfitting:\n",
    "\n",
    "    * decrease model complexity\n",
    "    * for example: decrease max depth, increase min samples per leaf\n",
    "    * gather more data\n",
    "\n",
    "##### Diagnose Bias Problems\n",
    "\n",
    "* If $\\hat{f}$ suffers from high bias: CV error of $\\hat{f}â‰ˆ$ training set error of $\\hat{f}>>$ desired error.\n",
    "\n",
    "* $\\hat{f}$ is said to underfit the training set. To remedy underfitting:\n",
    "\n",
    "* increase model complexity \n",
    "    * for example: increase max depth\n",
    "    * decrease min samples per leaf\n",
    "    * gather more relevant features    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d404f78e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(392, 8)\n",
      "(392, 1)\n"
     ]
    }
   ],
   "source": [
    "y = cleaned_auto['displ'].values\n",
    "y = y.reshape(-1,1)\n",
    "print(X.shape)\n",
    "X = cleaned_auto.drop('displ', axis=1)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "45e1d8dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>displ</th>\n",
       "      <th>hp</th>\n",
       "      <th>weight</th>\n",
       "      <th>accel</th>\n",
       "      <th>size</th>\n",
       "      <th>Asia</th>\n",
       "      <th>Europe</th>\n",
       "      <th>US</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>88</td>\n",
       "      <td>3139</td>\n",
       "      <td>14.5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>193</td>\n",
       "      <td>4732</td>\n",
       "      <td>18.5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.1</td>\n",
       "      <td>91.0</td>\n",
       "      <td>60</td>\n",
       "      <td>1800</td>\n",
       "      <td>16.4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.5</td>\n",
       "      <td>250.0</td>\n",
       "      <td>98</td>\n",
       "      <td>3525</td>\n",
       "      <td>19.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34.3</td>\n",
       "      <td>97.0</td>\n",
       "      <td>78</td>\n",
       "      <td>2188</td>\n",
       "      <td>15.8</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  displ   hp  weight  accel  size  Asia  Europe  US\n",
       "0  18.0  250.0   88    3139   14.5  15.0     0       0   1\n",
       "1   9.0  304.0  193    4732   18.5  20.0     0       0   1\n",
       "2  36.1   91.0   60    1800   16.4  10.0     1       0   0\n",
       "3  18.5  250.0   98    3525   19.0  15.0     0       0   1\n",
       "4  34.3   97.0   78    2188   15.8  10.0     0       1   0"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_auto.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "47c6b90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Set seed for reproducibility\n",
    "SEED = 123\n",
    "# Split data into 70% train and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=SEED)\n",
    "\n",
    "# Instantiate decision tree regressor and assign it to 'dt'\n",
    "dt = DecisionTreeRegressor(max_depth=4,\n",
    "                           min_samples_leaf=0.14, \n",
    "                           random_state=SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d3023a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the list of MSE ontained by 10-fold CV \n",
    "# Set n_jobs to -1 in order to exploit all CPU cores in computation\n",
    "MSE_CV = - cross_val_score(dt, X_train, y_train, cv= 10,\n",
    "                           scoring='neg_mean_squared_error',\n",
    "                           n_jobs = -1)\n",
    "# Fit 'dt' to the training set\n",
    "dt.fit(X_train, y_train)\n",
    "# Predict the labels of training set\n",
    "y_predict_train = dt.predict(X_train)\n",
    "# Predict the labels of test set\n",
    "y_predict_test = dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "367c82a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV MSE: 1016.06\n"
     ]
    }
   ],
   "source": [
    "# CV MSE  \n",
    "print('CV MSE: {:.2f}'.format(MSE_CV.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2846f21c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: 937.23\n"
     ]
    }
   ],
   "source": [
    "# Training set MSE\n",
    "print('Train MSE: {:.2f}'.format(MSE(y_train, y_predict_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "71897dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 778.94\n"
     ]
    }
   ],
   "source": [
    "# Test set MSE\n",
    "print('Test MSE: {:.2f}'.format(MSE(y_test, y_predict_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcd677d",
   "metadata": {},
   "source": [
    "### Instantiate the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3d88c307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>displ</th>\n",
       "      <th>hp</th>\n",
       "      <th>weight</th>\n",
       "      <th>accel</th>\n",
       "      <th>size</th>\n",
       "      <th>Asia</th>\n",
       "      <th>Europe</th>\n",
       "      <th>US</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>88</td>\n",
       "      <td>3139</td>\n",
       "      <td>14.5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>193</td>\n",
       "      <td>4732</td>\n",
       "      <td>18.5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.1</td>\n",
       "      <td>91.0</td>\n",
       "      <td>60</td>\n",
       "      <td>1800</td>\n",
       "      <td>16.4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.5</td>\n",
       "      <td>250.0</td>\n",
       "      <td>98</td>\n",
       "      <td>3525</td>\n",
       "      <td>19.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34.3</td>\n",
       "      <td>97.0</td>\n",
       "      <td>78</td>\n",
       "      <td>2188</td>\n",
       "      <td>15.8</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  displ   hp  weight  accel  size  Asia  Europe  US\n",
       "0  18.0  250.0   88    3139   14.5  15.0     0       0   1\n",
       "1   9.0  304.0  193    4732   18.5  20.0     0       0   1\n",
       "2  36.1   91.0   60    1800   16.4  10.0     1       0   0\n",
       "3  18.5  250.0   98    3525   19.0  15.0     0       0   1\n",
       "4  34.3   97.0   78    2188   15.8  10.0     0       1   0"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_auto.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e491ff93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(392,)\n"
     ]
    }
   ],
   "source": [
    "y = cleaned_auto['mpg'].values\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f0bddeec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>displ</th>\n",
       "      <th>hp</th>\n",
       "      <th>weight</th>\n",
       "      <th>accel</th>\n",
       "      <th>size</th>\n",
       "      <th>Asia</th>\n",
       "      <th>Europe</th>\n",
       "      <th>US</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250.0</td>\n",
       "      <td>88</td>\n",
       "      <td>3139</td>\n",
       "      <td>14.5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>304.0</td>\n",
       "      <td>193</td>\n",
       "      <td>4732</td>\n",
       "      <td>18.5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>91.0</td>\n",
       "      <td>60</td>\n",
       "      <td>1800</td>\n",
       "      <td>16.4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>250.0</td>\n",
       "      <td>98</td>\n",
       "      <td>3525</td>\n",
       "      <td>19.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>97.0</td>\n",
       "      <td>78</td>\n",
       "      <td>2188</td>\n",
       "      <td>15.8</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   displ   hp  weight  accel  size  Asia  Europe  US\n",
       "0  250.0   88    3139   14.5  15.0     0       0   1\n",
       "1  304.0  193    4732   18.5  20.0     0       0   1\n",
       "2   91.0   60    1800   16.4  10.0     1       0   0\n",
       "3  250.0   98    3525   19.0  15.0     0       0   1\n",
       "4   97.0   78    2188   15.8  10.0     0       1   0"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = cleaned_auto.drop('mpg', axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "eb44a014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train_test_split from sklearn.model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set SEED for reproducibility\n",
    "SEED = 1\n",
    "\n",
    "# Split the data into 70% train and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=SEED)\n",
    "\n",
    "# Instantiate a DecisionTreeRegressor dt\n",
    "dt = DecisionTreeRegressor(max_depth=4, min_samples_leaf=0.26, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cada06",
   "metadata": {},
   "source": [
    "### Evaluate the 10-fold CV error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "912d4386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV RMSE: 5.14\n"
     ]
    }
   ],
   "source": [
    "# Compute the array containing the 10-folds CV MSEs\n",
    "MSE_CV_scores = - cross_val_score(dt,  X_train, y_train, cv=10, \n",
    "                       scoring='neg_mean_squared_error',\n",
    "                       n_jobs=-1)\n",
    "\n",
    "# Compute the 10-folds CV RMSE\n",
    "RMSE_CV = (MSE_CV_scores.mean())**(1/2)\n",
    "\n",
    "# Print RMSE_CV\n",
    "print('CV RMSE: {:.2f}'.format(RMSE_CV))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b08a0c",
   "metadata": {},
   "source": [
    "> A very good practice is to keep the test set untouched until you are confident about your model's performance. CV is a great technique to get an estimate of a model's performance without affecting the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f89a5a4",
   "metadata": {},
   "source": [
    "### Evaluate the training error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "4efc9a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 5.15\n"
     ]
    }
   ],
   "source": [
    "# Import mean_squared_error from sklearn.metrics as MSE\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "# Fit dt to the training set\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the training set\n",
    "y_pred_train = dt.predict(X_train)\n",
    "\n",
    "# Evaluate the training set RMSE of dt\n",
    "RMSE_train = (MSE(y_train, y_pred_train))**(1/2)\n",
    "\n",
    "# Print RMSE_train\n",
    "print('Train RMSE: {:.2f}'.format(RMSE_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4abfa8",
   "metadata": {},
   "source": [
    "> Notice how the training error is roughly equal to the 10-folds CV error you obtained in the previous exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc02604",
   "metadata": {},
   "source": [
    "### High bias or high variance?\n",
    "**If we would have a `baseline_RMSE` of 5.1**\n",
    "\n",
    "\n",
    "**dt suffers from high bias because RMSE_CV  RMSE_train and both scores are greater than `baseline_RMSE`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced65635",
   "metadata": {},
   "source": [
    "## Ensemble Learning\n",
    "\n",
    "\n",
    "### Advantages of CARTs\n",
    "\n",
    "* Simple to understand.\n",
    "* Simple to interpret.\n",
    "* Easy to use.\n",
    "* Flexibility: ability to describe non-linear dependencies. \n",
    "* Preprocessing: no need to standardize or normalize features.\n",
    "\n",
    "### Limitations of CARTs\n",
    "\n",
    "* Classification: can only produce orthogonal decision boundaries.\n",
    "* Sensitive to small variations in the training set.\n",
    "* High variance: unconstrained CARTs may overfit the training set.\n",
    "* **Solution: ensemble learning.**\n",
    "\n",
    "### Ensemble Learning\n",
    "\n",
    "* Train different models on the same dataset.\n",
    "* Let each model make its predictions.\n",
    "* Meta-model: aggregates predictions of i ndividual models.\n",
    "* Final prediction: more robust and less prone to errors.\n",
    "* Best results: models are skillful in different ways.\n",
    "\n",
    "#### Ensemble Learning in Practice: Voting Classifier \n",
    "\n",
    "* Binary classication task.\n",
    "* $N$ classfiers make predictions: $P_{1},P_{2},...,P_{n}$ with $P=0$or 1.\n",
    "* Meta-model prediction: hard voting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a79bee18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import functions to compute accuracy and split data\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Import models, including VotingClassifier meta-model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "# Set seed for reproducibility\n",
    "SEED = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f7225bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "wbc = pd.read_csv('wbc.csv')\n",
    "wbc['Diagnosis_num'] = wbc['diagnosis'].map({'B':0, 'M':1})\n",
    "X = wbc[['radius_mean', 'concave points_mean']].values\n",
    "y = wbc['Diagnosis_num'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "e09a7af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into 70% train and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size= 0.3,\n",
    "                                                    random_state= SEED)\n",
    "# Instantiate individual classifiers\n",
    "lr = LogisticRegression(random_state=SEED)\n",
    "knn = KNN()\n",
    "dt = DecisionTreeClassifier(random_state=SEED)\n",
    "# Define a list called classifier that contains the tuples (classifier_name, classifier)\n",
    "classifiers = [('Logistic Regression', lr),                \n",
    "               ('K Nearest Neighbours', knn),              \n",
    "               ('Classification Tree', dt)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "016100c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression : 0.848\n",
      "K Nearest Neighbours : 0.883\n",
      "Classification Tree : 0.901\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the defined list of tuples containing the classifiers\n",
    "for clf_name, clf in classifiers:\n",
    "    #fit clf to the training set    \n",
    "    clf.fit(X_train, y_train)\n",
    "    # Predict the labels of the test set    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    # Evaluate the accuracy of clf on the test set\n",
    "    print('{:s} : {:.3f}'.format(clf_name, accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "e3b839cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier: 0.8947368421052632\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a VotingClassifier 'vc'\n",
    "vc = VotingClassifier(estimators=classifiers) \n",
    "# Fit 'vc' to the traing set and predict test set labels\n",
    "vc.fit(X_train, y_train)   \n",
    "y_pred = vc.predict(X_test)\n",
    "# Evaluate the test-set accuracy of 'vc'\n",
    "print('Voting Classifier: {}'.format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af390440",
   "metadata": {},
   "source": [
    "### Define the ensemble\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "6dca388c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age_std</th>\n",
       "      <th>Total_Bilirubin_std</th>\n",
       "      <th>Direct_Bilirubin_std</th>\n",
       "      <th>Alkaline_Phosphotase_std</th>\n",
       "      <th>Alamine_Aminotransferase_std</th>\n",
       "      <th>Aspartate_Aminotransferase_std</th>\n",
       "      <th>Total_Protiens_std</th>\n",
       "      <th>Albumin_std</th>\n",
       "      <th>Albumin_and_Globulin_Ratio_std</th>\n",
       "      <th>Is_male_std</th>\n",
       "      <th>Liver_disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.247403</td>\n",
       "      <td>-0.420320</td>\n",
       "      <td>-0.495414</td>\n",
       "      <td>-0.428870</td>\n",
       "      <td>-0.355832</td>\n",
       "      <td>-0.319111</td>\n",
       "      <td>0.293722</td>\n",
       "      <td>0.203446</td>\n",
       "      <td>-0.147390</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.062306</td>\n",
       "      <td>1.218936</td>\n",
       "      <td>1.423518</td>\n",
       "      <td>1.675083</td>\n",
       "      <td>-0.093573</td>\n",
       "      <td>-0.035962</td>\n",
       "      <td>0.939655</td>\n",
       "      <td>0.077462</td>\n",
       "      <td>-0.648461</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.062306</td>\n",
       "      <td>0.640375</td>\n",
       "      <td>0.926017</td>\n",
       "      <td>0.816243</td>\n",
       "      <td>-0.115428</td>\n",
       "      <td>-0.146459</td>\n",
       "      <td>0.478274</td>\n",
       "      <td>0.203446</td>\n",
       "      <td>-0.178707</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.815511</td>\n",
       "      <td>-0.372106</td>\n",
       "      <td>-0.388807</td>\n",
       "      <td>-0.449416</td>\n",
       "      <td>-0.366760</td>\n",
       "      <td>-0.312205</td>\n",
       "      <td>0.293722</td>\n",
       "      <td>0.329431</td>\n",
       "      <td>0.165780</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.679294</td>\n",
       "      <td>0.093956</td>\n",
       "      <td>0.179766</td>\n",
       "      <td>-0.395996</td>\n",
       "      <td>-0.295731</td>\n",
       "      <td>-0.177537</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>-0.930414</td>\n",
       "      <td>-1.713237</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age_std  Total_Bilirubin_std  Direct_Bilirubin_std  \\\n",
       "0  1.247403            -0.420320             -0.495414   \n",
       "1  1.062306             1.218936              1.423518   \n",
       "2  1.062306             0.640375              0.926017   \n",
       "3  0.815511            -0.372106             -0.388807   \n",
       "4  1.679294             0.093956              0.179766   \n",
       "\n",
       "   Alkaline_Phosphotase_std  Alamine_Aminotransferase_std  \\\n",
       "0                 -0.428870                     -0.355832   \n",
       "1                  1.675083                     -0.093573   \n",
       "2                  0.816243                     -0.115428   \n",
       "3                 -0.449416                     -0.366760   \n",
       "4                 -0.395996                     -0.295731   \n",
       "\n",
       "   Aspartate_Aminotransferase_std  Total_Protiens_std  Albumin_std  \\\n",
       "0                       -0.319111            0.293722     0.203446   \n",
       "1                       -0.035962            0.939655     0.077462   \n",
       "2                       -0.146459            0.478274     0.203446   \n",
       "3                       -0.312205            0.293722     0.329431   \n",
       "4                       -0.177537            0.755102    -0.930414   \n",
       "\n",
       "   Albumin_and_Globulin_Ratio_std  Is_male_std  Liver_disease  \n",
       "0                       -0.147390            0              1  \n",
       "1                       -0.648461            1              1  \n",
       "2                       -0.178707            1              1  \n",
       "3                        0.165780            1              1  \n",
       "4                       -1.713237            1              1  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liver = pd.read_csv('indian_liver_patient/indian_liver_patient_preprocessed.csv', index_col=0)\n",
    "liver.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "542a6829",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = liver.drop('Liver_disease', axis=1)\n",
    "y = liver['Liver_disease']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "28b50c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into 70% train and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size= 0.3,\n",
    "                                                    random_state= SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "f51dd083",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Logistic Regression', LogisticRegression(random_state=1)),\n",
       " ('K Nearest Neighbours', KNeighborsClassifier(n_neighbors=27)),\n",
       " ('Classification Tree',\n",
       "  DecisionTreeClassifier(min_samples_leaf=0.13, random_state=1))]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set seed for reproducibility\n",
    "SEED=1\n",
    "\n",
    "# Instantiate lr\n",
    "lr = LogisticRegression(random_state=SEED)\n",
    "\n",
    "# Instantiate knn\n",
    "knn = KNN(n_neighbors=27)\n",
    "\n",
    "# Instantiate dt\n",
    "dt = DecisionTreeClassifier(min_samples_leaf=0.13, random_state=SEED)\n",
    "\n",
    "# Define the list classifiers\n",
    "classifiers = [('Logistic Regression', lr), ('K Nearest Neighbours', knn), ('Classification Tree', dt)]\n",
    "classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8df39a",
   "metadata": {},
   "source": [
    "### Evaluate individual classifiers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "ab239875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression : 0.759\n",
      "K Nearest Neighbours : 0.701\n",
      "Classification Tree : 0.730\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the pre-defined list of classifiers\n",
    "for clf_name, clf in classifiers:    \n",
    " \n",
    "    # Fit clf to the training set\n",
    "    clf.fit(X_train, y_train)    \n",
    "   \n",
    "    # Predict y_pred\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred) \n",
    "   \n",
    "    # Evaluate clf's accuracy on the test set\n",
    "    print('{:s} : {:.3f}'.format(clf_name, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80692936",
   "metadata": {},
   "source": [
    "> Notice how Logistic Regression achieved the highest accuracy of 75.9%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd120eb",
   "metadata": {},
   "source": [
    "### Better performance with a Voting Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "5f04d9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier: 0.770\n"
     ]
    }
   ],
   "source": [
    "# Import VotingClassifier from sklearn.ensemble\n",
    "from sklearn.ensemble import VotingClassifier \n",
    "\n",
    "# Instantiate a VotingClassifier vc\n",
    "vc = VotingClassifier(estimators=classifiers)     \n",
    "\n",
    "# Fit vc to the training set\n",
    "vc.fit(X_train, y_train)   \n",
    "\n",
    "# Evaluate the test set predictions\n",
    "y_pred = vc.predict(X_test)\n",
    "\n",
    "# Calculate accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Voting Classifier: {:.3f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcb6e7e",
   "metadata": {},
   "source": [
    "> Notice how the voting classifier achieves a test set accuracy of 77%. This value is greater than that achieved by `LogisticRegression`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d20a79a",
   "metadata": {},
   "source": [
    "# 3. Bagging and Random Forests\n",
    "## Bagging\n",
    "\n",
    "**Ensemble Methods**\n",
    "\n",
    "* **Voting Classier**\n",
    "\n",
    "> Same training set\n",
    "\n",
    "> $â‰ $ algorithms.\n",
    "\n",
    "* **Bagging**\n",
    "\n",
    "> One algorithm\n",
    "\n",
    "> $â‰ $ subsets of the training set.\n",
    "\n",
    "\n",
    "### Bagging\n",
    "\n",
    "* **Bagging:** Bootstrap Aggregation.\n",
    "\n",
    "* Uses a technique known as the bootstrap.\n",
    "\n",
    "* Reduces variance of individual models in the ensemble.\n",
    "\n",
    "\n",
    "### Bagging: Classification & Regression\n",
    "\n",
    "**Classication:** \n",
    "* Aggregates predictions by majority voting.\n",
    "* `BaggingClassifier` in scikit-learn.\n",
    "\n",
    "**Regression:**\n",
    "* Aggregates predictions through averaging.\n",
    "* `BaggingRegressor` in scikit-learn.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04466ca",
   "metadata": {},
   "source": [
    "### Bagging Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "5dcfbc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wbc = pd.read_csv('wbc.csv')\n",
    "wbc['Diagnosis_num'] = wbc['diagnosis'].map({'B':0, 'M':1})\n",
    "X = wbc[['radius_mean', 'concave points_mean']].values\n",
    "y = wbc['Diagnosis_num'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "f0c5c43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import models and utility functions\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set seed for reproducibility\n",
    "SEED = 1\n",
    "# Split data into 70% train and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "f00d3b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Bagging Classifier: 0.877\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a classification-tree 'dt'\n",
    "dt = DecisionTreeClassifier(max_depth=4, min_samples_leaf=0.16, random_state=SEED)\n",
    "# Instantiate a BaggingClassifier 'bc'\n",
    "bc = BaggingClassifier(base_estimator=dt, n_estimators=300, n_jobs=-1)\n",
    "# Fit 'bc' to the training set\n",
    "bc.fit(X_train, y_train)\n",
    "# Predict test set labels\n",
    "y_pred = bc.predict(X_test)\n",
    "# Evaluate and print test-set accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy of Bagging Classifier: {:.3f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afda9361",
   "metadata": {},
   "source": [
    "### Define the bagging classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "46e29c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Import BaggingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# Instantiate dt\n",
    "dt = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "# Instantiate bc\n",
    "bc = BaggingClassifier(base_estimator=dt, n_estimators=50, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "92821d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = liver.drop('Liver_disease', axis=1)\n",
    "y = liver['Liver_disease']\n",
    "\n",
    "# Split data into 70% train and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size= 0.3,\n",
    "                                                    random_state= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "ac5265fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy of bc: 0.70\n"
     ]
    }
   ],
   "source": [
    "# Fit bc to the training set\n",
    "bc.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = bc.predict(X_test)\n",
    "\n",
    "# Evaluate acc_test\n",
    "acc_test = accuracy_score(y_test, y_pred)\n",
    "print('Test set accuracy of bc: {:.2f}'.format(acc_test)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7728a8cc",
   "metadata": {},
   "source": [
    "> A single tree dt would have achieved an accuracy of 63% which is 4% lower than bc's accuracy!\n",
    "\n",
    "## Out of Bag Evaluation\n",
    "\n",
    "\n",
    "**Bagging**\n",
    "\n",
    "* Some instances may be sampled several times for one model\n",
    "* Other instances may not be sampled at all\n",
    "\n",
    "**Out Of Bag(OOB) instances**\n",
    "* Onaverage, for each model, 63% of the training instances are sampled.\n",
    "* The remaining 37% constitute the OOB instances.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "8586d30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wbc = pd.read_csv('wbc.csv')\n",
    "wbc['Diagnosis_num'] = wbc['diagnosis'].map({'B':0, 'M':1})\n",
    "X = wbc[['radius_mean', 'concave points_mean']].values\n",
    "y = wbc['Diagnosis_num'].values\n",
    "\n",
    "# Import models and split utility function\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Set seed for reproducibility\n",
    "SEED = 1\n",
    "# Split data into 70% train and 30% test\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X, y, test_size= 0.3,\n",
    "                                                     stratify= y, \n",
    "                                                     random_state=SEED)\n",
    "\n",
    "# Instantiate a classification-tree 'dt'\n",
    "dt = DecisionTreeClassifier(max_depth=4,\n",
    "                            min_samples_leaf=0.16,\n",
    "                            random_state=SEED)\n",
    "# Instantiate a BaggingClassifier 'bc'; set oob_score = True \n",
    "bc = BaggingClassifier(base_estimator=dt, n_estimators=300,\n",
    "                       oob_score=True, n_jobs=-1)\n",
    "# Fit 'bc' to the training set\n",
    "bc.fit(X_train, y_train)\n",
    "# Predict the test set labels\n",
    "y_pred = bc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "d8e6dfff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.877\n",
      "OOB accuracy: 0.915\n"
     ]
    }
   ],
   "source": [
    "# Evaluate test set accuracy\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "# Extract the OOB accuracy from 'bc'\n",
    "oob_accuracy = bc.oob_score_\n",
    "# Print test set accuracy\n",
    "print('Test set accuracy: {:.3f}'.format(test_accuracy))\n",
    "# Print OOB accuracy\n",
    "print('OOB accuracy: {:.3f}'.format(oob_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7aa31c3",
   "metadata": {},
   "source": [
    "### Prepare the ground\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "c5119617",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = liver.drop('Liver_disease', axis=1)\n",
    "y = liver['Liver_disease']\n",
    "\n",
    "# Split data into 70% train and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size= 0.3,\n",
    "                                                    random_state= 1)\n",
    "# Import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Import BaggingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# Instantiate dt\n",
    "dt = DecisionTreeClassifier(min_samples_leaf=8, random_state=1)\n",
    "\n",
    "# Instantiate bc\n",
    "bc = BaggingClassifier(base_estimator=dt, \n",
    "            n_estimators=50,\n",
    "            oob_score=True,\n",
    "            random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ee8781",
   "metadata": {},
   "source": [
    "### OOB Score vs Test Set Score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "0f8a2736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.707, OOB accuracy: 0.677\n"
     ]
    }
   ],
   "source": [
    "# Fit bc to the training set \n",
    "bc.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = bc.predict(X_test)\n",
    "\n",
    "# Evaluate test set accuracy\n",
    "acc_test = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Evaluate OOB accuracy\n",
    "acc_oob = bc.oob_score_\n",
    "\n",
    "# Print acc_test and acc_oob\n",
    "print('Test set accuracy: {:.3f}, OOB accuracy: {:.3f}'.format(acc_test, acc_oob))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385c05ba",
   "metadata": {},
   "source": [
    "> The test set accuracy and the OOB accuracy of bc are both roughly equal to 70%!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c10e26",
   "metadata": {},
   "source": [
    "## Random Forests (RF)\n",
    "\n",
    "\n",
    "**Bagging**\n",
    "* Base estimator: Decision Tree, Logistic Regression, NeuralNet,...\n",
    "* Each estimator is trained on a distinct bootstrap sample of the training set \n",
    "* Estimators use all features for training and prediction\n",
    "\n",
    "**Further Diversity with Random Forests**\n",
    "\n",
    "* Base estimator: Decision Tree \n",
    "* Each estimator is trained on a different bootstrap sample having the same size as the training set\n",
    "* RF introduces further randomization in the training of individual trees \n",
    "* $d$ features are sampled at each node without replacement ($d<total$ number of features)\n",
    "\n",
    "**Random Forests: Classification & Regression**\n",
    "\n",
    "**Classication:**\n",
    "* Aggregates predictions by majority voting\n",
    "* `RandomForestClassifier` inscikit-learn\n",
    "\n",
    "**Regression:**\n",
    "* Aggregates predictions through averaging\n",
    "* `RandomForestRegressor` in scikit-learn\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "8266748b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(392,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>displ</th>\n",
       "      <th>hp</th>\n",
       "      <th>weight</th>\n",
       "      <th>accel</th>\n",
       "      <th>size</th>\n",
       "      <th>Asia</th>\n",
       "      <th>Europe</th>\n",
       "      <th>US</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250.0</td>\n",
       "      <td>88</td>\n",
       "      <td>3139</td>\n",
       "      <td>14.5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>304.0</td>\n",
       "      <td>193</td>\n",
       "      <td>4732</td>\n",
       "      <td>18.5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>91.0</td>\n",
       "      <td>60</td>\n",
       "      <td>1800</td>\n",
       "      <td>16.4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>250.0</td>\n",
       "      <td>98</td>\n",
       "      <td>3525</td>\n",
       "      <td>19.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>97.0</td>\n",
       "      <td>78</td>\n",
       "      <td>2188</td>\n",
       "      <td>15.8</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   displ   hp  weight  accel  size  Asia  Europe  US\n",
       "0  250.0   88    3139   14.5  15.0     0       0   1\n",
       "1  304.0  193    4732   18.5  20.0     0       0   1\n",
       "2   91.0   60    1800   16.4  10.0     1       0   0\n",
       "3  250.0   98    3525   19.0  15.0     0       0   1\n",
       "4   97.0   78    2188   15.8  10.0     0       1   0"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = cleaned_auto['mpg'].values\n",
    "print(y.shape)\n",
    "X = cleaned_auto.drop('mpg', axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "708ca3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set RMSE of rf: 3.98\n"
     ]
    }
   ],
   "source": [
    "# Basic imports\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "# Set seed for reproducibility\n",
    "SEED = 1\n",
    "# Split dataset into 70% train and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=SEED)\n",
    "\n",
    "# Instantiate a random forests regressor 'rf' 400 estimators\n",
    "rf = RandomForestRegressor(n_estimators=400,\n",
    "                           min_samples_leaf=0.12,\n",
    "                           random_state=SEED)\n",
    "# Fit 'rf' to the training set\n",
    "rf.fit(X_train, y_train)\n",
    "# Predict the test set labels 'y_pred'\n",
    "y_pred = rf.predict(X_test)\n",
    "# Evaluate the test set RMSE\n",
    "rmse_test = MSE(y_test, y_pred)**(1/2)\n",
    "# Print the test set RMSE\n",
    "print('Test set RMSE of rf: {:.2f}'.format(rmse_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e2f6ea",
   "metadata": {},
   "source": [
    "#### Feature Importance\n",
    "Tree-based methods: enable measuring the importance of each feature in prediction.\n",
    "\n",
    "In `sklearn`:\n",
    "\n",
    "* how much the tree nodes use a particular feature (weightedaverage) to reduce impurity\n",
    "* accessed using the attribute `feature_importance_`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "83a07bfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Asia      0.000000\n",
       "Europe    0.000000\n",
       "US        0.000000\n",
       "accel     0.000024\n",
       "hp        0.167430\n",
       "dtype: float64"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# Create a pd.Series of features importances\n",
    "importances_rf = pd.Series(rf.feature_importances_, index = X.columns)\n",
    "# Sort importances_rf                                   \n",
    "sorted_importances_rf = importances_rf.sort_values()  \n",
    "sorted_importances_rf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "c0885253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make a horizontal bar plot\n",
    "sorted_importances_rf.plot(kind='barh', color='lightgreen'); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5607b06e",
   "metadata": {},
   "source": [
    "### Train an RF regressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "f4336423",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bikes = pd.read_csv('bikes.csv')\n",
    "y = bikes['cnt'].values\n",
    "X = bikes.drop('cnt', axis=1)\n",
    "\n",
    "\n",
    "# Set seed for reproducibility\n",
    "SEED = 1\n",
    "# Split dataset into 70% train and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "321e5729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(n_estimators=25, random_state=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_estimators=25, random_state=2)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(n_estimators=25, random_state=2)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Instantiate rf\n",
    "rf = RandomForestRegressor(n_estimators=25,\n",
    "            random_state=2)\n",
    "            \n",
    "# Fit rf to the training set    \n",
    "rf.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77d677d",
   "metadata": {},
   "source": [
    "### Evaluate the RF regressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "51211850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set RMSE of rf: 50.01\n"
     ]
    }
   ],
   "source": [
    "# Import mean_squared_error as MSE\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "# Predict the test set labels\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Evaluate the test set RMSE\n",
    "rmse_test = MSE(y_test, y_pred)**(1/2)\n",
    "\n",
    "# Print rmse_test\n",
    "print('Test set RMSE of rf: {:.2f}'.format(rmse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66cabfe",
   "metadata": {},
   "source": [
    "> You can try training a single CART on the same dataset. The test set RMSE achieved by rf is significantly smaller than that achieved by a single CART!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de5d231",
   "metadata": {},
   "source": [
    "### Visualizing features importances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "84226225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a pd.Series of features importances\n",
    "importances = pd.Series(data=rf.feature_importances_,\n",
    "                        index= X_train.columns)\n",
    "\n",
    "# Sort importances\n",
    "importances_sorted = importances.sort_values()  \n",
    "\n",
    "# Draw a horizontal barplot of importances_sorted\n",
    "importances_sorted.plot(kind='barh', color='lightgreen')\n",
    "plt.title('Features Importances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b17ea7",
   "metadata": {},
   "source": [
    "> Apparently, `hr` and `workingday` are the most important features according to `rf`. The importances of these two features add up to more than 90%!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d160980",
   "metadata": {},
   "source": [
    "# 4. Boosting\n",
    "\n",
    "## Adaboost\n",
    "\n",
    "\n",
    "**Boosting:** Ensemble method combining several weak learners to form a strong learner.\n",
    "**Weak learner:** Model doing slightly better than random guessing.\n",
    "* Example of weak learner: Decision stump (CART whose maximum depth is 1).\n",
    "\n",
    "**Boosting**\n",
    "\n",
    "* Train an ensemble of predictors sequentially.\n",
    "* Each predictor tries to correct its predecessor.\n",
    "* Most popularb oosting methods:\n",
    "    * AdaBoost\n",
    "    * GradientBoosting.\n",
    "\n",
    "\n",
    "**Adaboost**     \n",
    "* Stands for **Adaptive Boosting.**\n",
    "* Each predictor pays more attention to the instances wrongly predicted by its predecessor.\n",
    "* Achieved by changing the weights of training instances.\n",
    "* Each predictor is assigned a coefficient $Î±$.\n",
    "* $Î±$ depends on the predictor's training error.\n",
    "\n",
    "\n",
    "**AdaBoost:Prediction**\n",
    "\n",
    "Classification: \n",
    "* Weighted majority voting.\n",
    "* Insklearn: `AdaBoostClassifier`\n",
    "\n",
    "Regression:\n",
    "* Weighted average.\n",
    "* Insklearn: `AdaBoostRegressor`\n",
    "\n",
    "\n",
    "**Learning Rate**\n",
    "\n",
    "Learning rate: $0 < Î· â‰¤ 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "95116782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC score: 0.96\n"
     ]
    }
   ],
   "source": [
    "X = wbc[['radius_mean', 'concave points_mean']].values\n",
    "y = wbc['Diagnosis_num'].values\n",
    "\n",
    "# Import models and utility functions\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Set seed for reproducibility\n",
    "SEED = 1\n",
    "# Split data into 70% train and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,\n",
    "                                                    stratify=y, \n",
    "                                                    random_state=SEED)\n",
    "# Instantiate a classification-tree 'dt'\n",
    "dt = DecisionTreeClassifier(max_depth=1, random_state=SEED)\n",
    "# Instantiate an AdaBoost classifier 'adab_clf'\n",
    "adb_clf = AdaBoostClassifier(base_estimator=dt, n_estimators=100)\n",
    "# Fit 'adb_clf' to the training set\n",
    "adb_clf.fit(X_train, y_train)\n",
    "# Predict the test set probabilities of positive class\n",
    "y_pred_proba = adb_clf.predict_proba(X_test)[:,1]\n",
    "# Evaluate test-set roc_auc_score\n",
    "adb_clf_roc_auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "# Print adb_clf_roc_auc_score\n",
    "print('ROC AUC score: {:.2f}'.format(adb_clf_roc_auc_score)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69eb8862",
   "metadata": {},
   "source": [
    "### Define the AdaBoost classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "bf397ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = liver.drop('Liver_disease', axis=1)\n",
    "y = liver['Liver_disease']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
    "                                                    stratify=y, \n",
    "                                                    random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "a870c099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Import AdaBoostClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Instantiate dt\n",
    "dt = DecisionTreeClassifier(max_depth=2, random_state=1)\n",
    "\n",
    "# Instantiate ada\n",
    "ada = AdaBoostClassifier(base_estimator=dt, n_estimators=180, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895309e6",
   "metadata": {},
   "source": [
    "### Train the AdaBoost classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "3acc85fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.39625798, 0.50765614, 0.6427682 , 0.51103487, 0.48780342,\n",
       "       0.73943526, 0.76991857, 0.53736173, 0.4954065 , 0.73135885,\n",
       "       0.47717298, 0.50985453, 0.49507249, 0.49491357, 0.49728655,\n",
       "       0.5207147 , 0.65646446, 0.45504202, 0.52200441, 0.44185032,\n",
       "       0.55923564, 0.59414692, 0.53064697, 0.50853596, 0.54925712,\n",
       "       0.60424379, 0.54719743, 0.54350725, 0.50838599, 0.50969367,\n",
       "       0.45769971, 0.54814034, 0.51781017, 0.47897927, 0.45723668,\n",
       "       0.47955012, 0.52769609, 0.50896238, 0.7621668 , 0.43896318,\n",
       "       0.52957775, 0.70307692, 0.57273417, 0.47260877, 0.643982  ,\n",
       "       0.51904115, 0.4975862 , 0.56402374, 0.48282632, 0.51701353,\n",
       "       0.48170323, 0.45883632, 0.61314736, 0.51353514, 0.52761699,\n",
       "       0.50546511, 0.54698033, 0.53007825, 0.50862101, 0.65552032,\n",
       "       0.51483476, 0.6221994 , 0.59261553, 0.53532121, 0.60741196,\n",
       "       0.5081208 , 0.5046048 , 0.51254584, 0.76393968, 0.44109198,\n",
       "       0.7414859 , 0.44313599, 0.51089002, 0.54777615, 0.67033642,\n",
       "       0.60988767, 0.48709866, 0.52218285, 0.53682542, 0.51489516,\n",
       "       0.58353506, 0.44157533, 0.50390841, 0.53938872, 0.57187803,\n",
       "       0.49197572, 0.5141887 , 0.51310477, 0.50067422, 0.46315896,\n",
       "       0.76575657, 0.51398684, 0.49230341, 0.58604095, 0.55434773,\n",
       "       0.51942879, 0.60641421, 0.47575839, 0.62852501, 0.56391992,\n",
       "       0.5096715 , 0.48899115, 0.59725288, 0.62056711, 0.5259319 ,\n",
       "       0.78779407, 0.50748891, 0.48998984, 0.54299042, 0.51607412,\n",
       "       0.55688037, 0.52915404, 0.50831713, 0.74500046, 0.51189676,\n",
       "       0.47400584])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit ada to the training set\n",
    "ada.fit(X_train, y_train)\n",
    "\n",
    "# Compute the probabilities of obtaining the positive class\n",
    "y_pred_proba = ada.predict_proba(X_test)[:,1]\n",
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb82f6e9",
   "metadata": {},
   "source": [
    "> Next, we'll evaluate ada's ROC AUC score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3237a36",
   "metadata": {},
   "source": [
    "### Evaluate the AdaBoost classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "e22760aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC score: 0.69\n"
     ]
    }
   ],
   "source": [
    "# Import roc_auc_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Evaluate test-set roc_auc_score\n",
    "ada_roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# Print roc_auc_score\n",
    "print('ROC AUC score: {:.2f}'.format(ada_roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26a10a8",
   "metadata": {},
   "source": [
    "> This untuned AdaBoost classifier achieved a ROC AUC score of 0.69!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4828fd",
   "metadata": {},
   "source": [
    "## Gradient Boosting (GB)\n",
    "\n",
    "**Gradient Boosted Trees**\n",
    "* Sequential correction of predecessor's errors.\n",
    "* Does not tweak the weights of training instances.\n",
    "* Fit each predictor is trained using its predecessor's residual errors as labels.\n",
    "* Gradient Boosted Trees: a CART is used as a base learner.\n",
    "\n",
    "\n",
    "**Gradient Boosted Trees: Prediction** \n",
    "\n",
    "Regression:\n",
    "* $y_{pred}=y_{1}+Î·r_{1}+...+Î·r_{N}$\n",
    "* Insklearn:`GradientBoostingRegressor`.\n",
    "\n",
    "Classication:\n",
    "* Insklearn:`GradientBoostingClassifier`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "595d2959",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = cleaned_auto['mpg'].values\n",
    "X = cleaned_auto.drop('mpg', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "c12b5119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set RMSE: 4.01\n"
     ]
    }
   ],
   "source": [
    "# Import models and utility functions\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "#Set seed for reproducibility\n",
    "SEED = 1\n",
    "# Split dataset into 70% train and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, \n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=SEED)\n",
    "# Instantiate a GradientBoostingRegressor 'gbt'\n",
    "gbt = GradientBoostingRegressor(n_estimators=300, max_depth=1, random_state=SEED)\n",
    "# Fit 'gbt' to the training set\n",
    "gbt.fit(X_train, y_train)\n",
    "# Predict the test set labels\n",
    "y_pred = gbt.predict(X_test)\n",
    "# Evaluate the test set RMSE\n",
    "rmse_test = MSE(y_test, y_pred)**(1/2)\n",
    "# Print the test set RMSE\n",
    "print('Test set RMSE: {:.2f}'.format(rmse_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b374d2",
   "metadata": {},
   "source": [
    "### Define the GB regressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "02fb3fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes = pd.read_csv('bikes.csv')\n",
    "y = bikes['cnt'].values\n",
    "X = bikes.drop('cnt', axis=1)\n",
    "# Split dataset into 70% train and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, \n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "e03d0a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import GradientBoostingRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Instantiate gb\n",
    "gb = GradientBoostingRegressor(n_estimators=200, \n",
    "            max_depth=4,\n",
    "            random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b520e1e7",
   "metadata": {},
   "source": [
    "### Train the GB regressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "602ff875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit gb to the training set\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = gb.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3eaa98",
   "metadata": {},
   "source": [
    "### Evaluate the GB regressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "3db8d743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set RMSE of gb: 45.339\n"
     ]
    }
   ],
   "source": [
    "# Import mean_squared_error as MSE\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "# Compute MSE\n",
    "mse_test = MSE(y_test, y_pred)\n",
    "\n",
    "# Compute RMSE\n",
    "rmse_test = mse_test**(1/2)\n",
    "\n",
    "# Print RMSE\n",
    "print('Test set RMSE of gb: {:.3f}'.format(rmse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3490390",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Boosting (SGB)\n",
    "\n",
    "**Gradient Boosting: Cons**\n",
    "\n",
    "* GB involves an exhaustive search procedure.\n",
    "* Each CART is trained to find the best split points and features.\n",
    "* May lead to CARTs using the same split points and maybe the same features.\n",
    "\n",
    "\n",
    "**Stochastic Gradient Boosting**\n",
    "* Each tree is trained on a random subset of rows of the training data.\n",
    "* The sampled instances (40%-80%ofthetrainingset) are sampled without replacement.\n",
    "* Features are sampled (without replacement) when choosing split points.\n",
    "* Result: further ensemble diversity.\n",
    "* Effect: adding further variance to the ensemble of trees.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "1bd8d1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = cleaned_auto['mpg'].values\n",
    "X = cleaned_auto.drop('mpg', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "f18590e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set RMSE: 3.95\n"
     ]
    }
   ],
   "source": [
    "# Import models and utility functions\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "# Set seed for reproducibility\n",
    "SEED = 1\n",
    "# Split dataset into 70% train and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, \n",
    "                                                    test_size=0.3,    \n",
    "                                                    random_state=SEED)\n",
    "\n",
    "# Instantiate a stochastic GradientBoostingRegressor 'sgbt'\n",
    "sgbt = GradientBoostingRegressor(max_depth=1,\n",
    "                                 subsample=0.8,\n",
    "                                 max_features=0.2,\n",
    "                                 n_estimators=300, \n",
    "                                 random_state=SEED)\n",
    "# Fit 'sgbt' to the training set\n",
    "sgbt.fit(X_train, y_train)\n",
    "# Predict the test set labels\n",
    "y_pred = sgbt.predict(X_test)\n",
    "\n",
    "# Evaluate test set RMSE 'rmse_test'\n",
    "rmse_test = MSE(y_test, y_pred)**(1/2)\n",
    "# Print 'rmse_test'\n",
    "print('Test set RMSE: {:.2f}'.format(rmse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1edd56a",
   "metadata": {},
   "source": [
    "### Regression with SGB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "3d5add8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes = pd.read_csv('bikes.csv')\n",
    "y = bikes['cnt'].values\n",
    "X = bikes.drop('cnt', axis=1)\n",
    "# Split dataset into 80% train and 20% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, \n",
    "                                                    test_size=0.2,    \n",
    "                                                    random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "d73f1d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import GradientBoostingRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Instantiate sgbr\n",
    "sgbr = GradientBoostingRegressor(max_depth=4, \n",
    "            subsample=0.9,\n",
    "            max_features=0.75,\n",
    "            n_estimators=200,\n",
    "            random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5039ebe5",
   "metadata": {},
   "source": [
    "### Train the SGB regressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "e86b7a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit sgbr to the training set\n",
    "sgbr.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = sgbr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36da032e",
   "metadata": {},
   "source": [
    "### Evaluate the SGB regressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "89bb9c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set RMSE of sgbr: 45.143\n"
     ]
    }
   ],
   "source": [
    "# Import mean_squared_error as MSE\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "# Compute test set MSE\n",
    "mse_test = MSE(y_test, y_pred)\n",
    "\n",
    "# Compute test set RMSE\n",
    "rmse_test = mse_test**(1/2)\n",
    "\n",
    "# Print rmse_test\n",
    "print('Test set RMSE of sgbr: {:.3f}'.format(rmse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdef412",
   "metadata": {},
   "source": [
    "> The stochastic gradient boosting regressor achieves a lower test set RMSE than the gradient boosting regressor (which was 45.339)!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d80b227",
   "metadata": {},
   "source": [
    "# 5. Model Tuning\n",
    "\n",
    "## Tuning a CART's Hyperparameters\n",
    "\n",
    "**Hyperparameters**\n",
    "\n",
    "Machine learning model:\n",
    "* **parameters:** learned from data \n",
    "* CART example: split-point of a node, split-feature of a node ,...\n",
    "* **hyperparameters:** not learned from data, set prior to training \n",
    "* CART example: max_depth, min_samples_leaf, splitting criterion...\n",
    "\n",
    "\n",
    "**What is hyper parameter tuning?**\n",
    "* **Problem:** search for a set of optimal hyperparameters for a learning algorithm.\n",
    "* **Solution:** find a set of optimal hyperparameters that results in an optimal model.\n",
    "* **Optimalmodel:** yields an optimal score.\n",
    "* **Score:** in sklearn defaults to accuracy (classication) and $R^2$ (regression).\n",
    "* Cross validation is used to estimate the generalization performance.\n",
    "\n",
    "\n",
    "**Why tune hyperparameters?**\n",
    "* In sklearn, a model's default hyperparameters are not optimal for all problems.\n",
    "* Hyperparameters should be tuned to obtain the best model performance.\n",
    "\n",
    "**Approaches to hyperparameter tuning**\n",
    "* Grid Search\n",
    "* Random Search\n",
    "* Bayesian Optimization\n",
    "* Genetic Algorithms\n",
    "\n",
    "**Grid search cross validation**\n",
    "* Manually set a grid of discrete hyperparameter values.\n",
    "* Set a metric for scoring model performance.\n",
    "* Search exhaustively through the grid.\n",
    "* For each set of hyperparameters, evaluate eachmodel's CV score.\n",
    "* The optimal hyperparameters are those of the model achieving the best CV score.\n",
    "\n",
    "**Grid search cross validation: example**\n",
    "* Hyperparameters grids:\n",
    "    * `max_depth`={2,3,4},\n",
    "    * `min_samples_leaf`={0.05,0.1}\n",
    "* hyperparameterspace={(2,0.05),(2,0.1),(3,0.05),...}\n",
    "* CVscores=${score_{(2,0.05)},...}$\n",
    "* optimal hyperparameters = set of hyperparameters corresponding to the best CVscore.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "4c9bdadc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 1, 'splitter': 'best'}\n"
     ]
    }
   ],
   "source": [
    "# Import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# Set seed to 1 for reproducibility\n",
    "SEED = 1\n",
    "# Instantiate a DecisionTreeClassifier 'dt'\n",
    "dt = DecisionTreeClassifier(random_state=SEED)\n",
    "# Print out 'dt's hyperparameters\n",
    "print(dt.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "6e111659",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = wbc[['radius_mean', 'concave points_mean']].values\n",
    "y = wbc['Diagnosis_num'].values\n",
    "\n",
    "# Split dataset into 80% train and 20% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, \n",
    "                                                    test_size=0.2,    \n",
    "                                                    random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "d9489bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyerparameters:\n",
      " {'max_depth': 5, 'max_features': 0.2, 'min_samples_leaf': 0.04}\n"
     ]
    }
   ],
   "source": [
    "# Import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Define the grid of hyperparameters 'params_dt'\n",
    "params_dt = {'max_depth': [3, 4,5, 6],\n",
    "             'min_samples_leaf': [0.04, 0.06, 0.08],\n",
    "             'max_features': [0.2, 0.4,0.6, 0.8]            \n",
    "            }\n",
    "\n",
    "# Instantiate a 10-fold CV grid search object 'grid_dt'\n",
    "grid_dt = GridSearchCV(estimator=dt,\n",
    "                       param_grid=params_dt,\n",
    "                       scoring='accuracy', \n",
    "                       cv=10,\n",
    "                       n_jobs=-1)\n",
    "\n",
    "# Fit 'grid_dt' to the training data\n",
    "grid_dt.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Extract best hyperparameters from 'grid_dt'\n",
    "best_hyperparams = grid_dt.best_params_\n",
    "print('Best hyerparameters:\\n', best_hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "15139f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV accuracy 0.9101449275362319\n"
     ]
    }
   ],
   "source": [
    "# Extract best CV score from 'grid_dt'\n",
    "best_CV_score = grid_dt.best_score_\n",
    "print('Best CV accuracy {}'.format(best_CV_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "97411fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy of best model: 0.886\n"
     ]
    }
   ],
   "source": [
    "# Extract best model from 'grid_dt'\n",
    "best_model = grid_dt.best_estimator_\n",
    "# Evaluate test set accuracy\n",
    "test_acc = best_model.score(X_test,y_test)\n",
    "# Print test set accuracy\n",
    "print(\"Test set accuracy of best model: {:.3f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce6fa72",
   "metadata": {},
   "source": [
    "### Set the tree's hyperparameter grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "a4ba8435",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = liver.drop('Liver_disease', axis=1)\n",
    "y = liver['Liver_disease']\n",
    "\n",
    "# Split data into 70% train and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size= 0.3,\n",
    "                                                    random_state= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "474429ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define params_dt\n",
    "params_dt = {'max_depth': [2,3,4],\n",
    "             'min_samples_leaf': [0.12, 0.14, 0.16, 0.18]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5dde1d",
   "metadata": {},
   "source": [
    "### Search for the optimal tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "87920e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Instantiate grid_dt\n",
    "grid_dt = GridSearchCV(estimator=dt,\n",
    "                       param_grid=params_dt,\n",
    "                       scoring='roc_auc',\n",
    "                       cv=5,\n",
    "                       n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8632521",
   "metadata": {},
   "source": [
    "### Evaluate the optimal tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "1bfbb046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=DecisionTreeClassifier(random_state=1), n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [2, 3, 4],\n",
       "                         &#x27;min_samples_leaf&#x27;: [0.12, 0.14, 0.16, 0.18]},\n",
       "             scoring=&#x27;roc_auc&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=DecisionTreeClassifier(random_state=1), n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [2, 3, 4],\n",
       "                         &#x27;min_samples_leaf&#x27;: [0.12, 0.14, 0.16, 0.18]},\n",
       "             scoring=&#x27;roc_auc&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=1)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(random_state=1), n_jobs=-1,\n",
       "             param_grid={'max_depth': [2, 3, 4],\n",
       "                         'min_samples_leaf': [0.12, 0.14, 0.16, 0.18]},\n",
       "             scoring='roc_auc')"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "cfa04490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set ROC AUC score: 0.707\n"
     ]
    }
   ],
   "source": [
    "# Import roc_auc_score from sklearn.metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Extract the best estimator\n",
    "best_model = grid_dt.best_estimator_\n",
    "\n",
    "# Predict the test set probabilities of the positive class\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Compute test_roc_auc\n",
    "test_roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# Print test_roc_auc\n",
    "print('Test set ROC AUC score: {:.3f}'.format(test_roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ed4775",
   "metadata": {},
   "source": [
    "## Tuning a RF's Hyperparameters\n",
    "\n",
    "\n",
    "**Random Forests Hyperparameters**\n",
    "\n",
    "* CART hyperparameters\n",
    "* number of estimators\n",
    "* bootstrap\n",
    "\n",
    "\n",
    "**Tuning is expensive**\n",
    "\n",
    "Hyperparameter tuning:\n",
    "* computationally expensive,\n",
    "* sometimes leads to very slight improvement\n",
    "\n",
    "Weight the impact of tuning on the whole project.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "508f7883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'criterion': 'squared_error',\n",
       " 'max_depth': None,\n",
       " 'max_features': 1.0,\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': 1,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import RandomForestRegressor \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Set seed for reproducibility\n",
    "SEED = 1\n",
    "# Instantiate a random forests regressor 'rf' \n",
    "rf = RandomForestRegressor(random_state= SEED)\n",
    "# Inspect rf' s hyperparameters\n",
    "rf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "25d2d2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = wbc[['radius_mean', 'concave points_mean']].values\n",
    "y = wbc['Diagnosis_num'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size= 0.2,\n",
    "                                                    random_state= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "26dd27f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Define a grid of hyperparameter 'params_rf'\n",
    "params_rf = {'n_estimators': [300, 400, 500],\n",
    "             'max_depth': [4, 6, 8],\n",
    "             'min_samples_leaf': [0.1, 0.2],\n",
    "             'max_features': ['log2', 'sqrt']             \n",
    "            }\n",
    "# Instantiate 'grid_rf'\n",
    "grid_rf = GridSearchCV(estimator=rf,\n",
    "                       param_grid=params_rf,\n",
    "                       cv=3,\n",
    "                       scoring='neg_mean_squared_error',\n",
    "                       verbose=1, \n",
    "                       n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "5a1a4d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=RandomForestRegressor(random_state=1), n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [4, 6, 8],\n",
       "                         &#x27;max_features&#x27;: [&#x27;log2&#x27;, &#x27;sqrt&#x27;],\n",
       "                         &#x27;min_samples_leaf&#x27;: [0.1, 0.2],\n",
       "                         &#x27;n_estimators&#x27;: [300, 400, 500]},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3, estimator=RandomForestRegressor(random_state=1), n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [4, 6, 8],\n",
       "                         &#x27;max_features&#x27;: [&#x27;log2&#x27;, &#x27;sqrt&#x27;],\n",
       "                         &#x27;min_samples_leaf&#x27;: [0.1, 0.2],\n",
       "                         &#x27;n_estimators&#x27;: [300, 400, 500]},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(random_state=1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(random_state=1)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestRegressor(random_state=1), n_jobs=-1,\n",
       "             param_grid={'max_depth': [4, 6, 8],\n",
       "                         'max_features': ['log2', 'sqrt'],\n",
       "                         'min_samples_leaf': [0.1, 0.2],\n",
       "                         'n_estimators': [300, 400, 500]},\n",
       "             scoring='neg_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit 'grid_rf' to the training set\n",
    "grid_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "fed321bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:\n",
      " {'max_depth': 4, 'max_features': 'log2', 'min_samples_leaf': 0.1, 'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "# Extract the best hyperparameters from 'grid_rf'\n",
    "best_hyperparams = grid_rf.best_params_\n",
    "print('Best hyperparameters:\\n', best_hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "910508e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set RMSE of rf: 0.26\n"
     ]
    }
   ],
   "source": [
    "# Extract the best model from 'grid_rf'\n",
    "best_model = grid_rf.best_estimator_\n",
    "# Predict the test set labels\n",
    "y_pred = best_model.predict(X_test)\n",
    "# Evaluate the test set RMSE\n",
    "rmse_test = MSE(y_test, y_pred)**(1/2)\n",
    "# Print the test set RMSE\n",
    "print('Test set RMSE of rf: {:.2f}'.format(rmse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe693e0",
   "metadata": {},
   "source": [
    "### Set the hyperparameter grid of RF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "1b383b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dictionary 'params_rf'\n",
    "params_rf = {'n_estimators': [100, 350, 500],\n",
    "             'min_samples_leaf': [2, 10, 30],\n",
    "             'max_features': ['log2', 'auto', 'sqrt']             \n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "bbd43598",
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes = pd.read_csv('bikes.csv')\n",
    "y = bikes['cnt'].values\n",
    "X = bikes.drop('cnt', axis=1)\n",
    "# Split dataset into 80% train and 20% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, \n",
    "                                                    test_size=0.2,    \n",
    "                                                    random_state=SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b54a98f",
   "metadata": {},
   "source": [
    "### Search for the optimal forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "4961d2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/opt/miniconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/opt/miniconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/opt/miniconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/opt/miniconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/opt/miniconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/opt/miniconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/opt/miniconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/opt/miniconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/opt/miniconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/opt/miniconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/opt/miniconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/opt/miniconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/opt/miniconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/opt/miniconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/opt/miniconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/opt/miniconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/opt/miniconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/opt/miniconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/opt/miniconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/opt/miniconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/opt/miniconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/opt/miniconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/opt/miniconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/opt/miniconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/opt/miniconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/opt/miniconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=RandomForestRegressor(random_state=1), n_jobs=-1,\n",
       "             param_grid={&#x27;max_features&#x27;: [&#x27;log2&#x27;, &#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                         &#x27;min_samples_leaf&#x27;: [2, 10, 30],\n",
       "                         &#x27;n_estimators&#x27;: [100, 350, 500]},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3, estimator=RandomForestRegressor(random_state=1), n_jobs=-1,\n",
       "             param_grid={&#x27;max_features&#x27;: [&#x27;log2&#x27;, &#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                         &#x27;min_samples_leaf&#x27;: [2, 10, 30],\n",
       "                         &#x27;n_estimators&#x27;: [100, 350, 500]},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(random_state=1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(random_state=1)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestRegressor(random_state=1), n_jobs=-1,\n",
       "             param_grid={'max_features': ['log2', 'auto', 'sqrt'],\n",
       "                         'min_samples_leaf': [2, 10, 30],\n",
       "                         'n_estimators': [100, 350, 500]},\n",
       "             scoring='neg_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Instantiate grid_rf\n",
    "grid_rf = GridSearchCV(estimator=rf,\n",
    "                       param_grid=params_rf,\n",
    "                       scoring='neg_mean_squared_error',\n",
    "                       cv=3,\n",
    "                       verbose=1,\n",
    "                       n_jobs=-1)\n",
    "grid_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c083e6",
   "metadata": {},
   "source": [
    "### Evaluate the optimal forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "12b169e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE of best model: 51.779\n"
     ]
    }
   ],
   "source": [
    "# Import mean_squared_error from sklearn.metrics as MSE \n",
    "from sklearn.metrics import mean_squared_error as MSE \n",
    "\n",
    "# Extract the best estimator\n",
    "best_model = grid_rf.best_estimator_\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Compute rmse_test\n",
    "rmse_test = MSE(y_test, y_pred)**(1/2)\n",
    "\n",
    "# Print rmse_test\n",
    "print('Test RMSE of best model: {:.3f}'.format(rmse_test)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
